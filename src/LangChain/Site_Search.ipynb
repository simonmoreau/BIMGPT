{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dfe691-baaa-478e-a273-939e2837a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "import os\n",
    "import getpass\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7529ceff-56f0-4465-9f79-f9208acdb788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "async def website_parser(base_url: str) -> list[Document]:\n",
    "    loader = RecursiveUrlLoader(\n",
    "        base_url,\n",
    "        extractor=bs4_extractor,\n",
    "        max_depth=2,\n",
    "        prevent_outside=True,\n",
    "        # use_async=False,\n",
    "        # extractor=None,\n",
    "        # metadata_extractor=None,\n",
    "        # exclude_dirs=(),\n",
    "        # timeout=10,\n",
    "        # check_response_status=True,\n",
    "        # continue_on_failure=True,\n",
    "        # \n",
    "        # base_url=None,\n",
    "        # ...\n",
    "    )\n",
    "    site_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        site_docs.append(doc)\n",
    "    return site_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff77ade-2921-4db9-b5e7-f334488763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore, VectorStoreRetriever\n",
    "\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "azureEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ebe41a-4803-4dad-af73-51270f376be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to create a vector store from an url\n",
    "async def vector_store_create(url: str) -> VectorStoreRetriever:\n",
    "    # Retrive the documents\n",
    "    website_docs = await website_parser(url)\n",
    "    website_docs\n",
    "    print(f\"{len(website_docs)} docs in {url}\")\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(website_docs)\n",
    "    print(f\"{len(chunks)} chunks in {url}\")\n",
    "    # Initialize with an embedding model\n",
    "    vector_store = InMemoryVectorStore(embedding=azureEmbeddings)\n",
    "    # Add embeddings into the vector store\n",
    "    vector_store.add_documents(documents=chunks)\n",
    "    retriever = vector_store.as_retriever() # uses similarity search by default\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c31472-ae52-4acf-bf09-b39c6df20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"Vous êtes un spécialiste de la gestion comptable des entreprises\"    \n",
    "    \"Dans le cadre de la généralisation de la facturation électronique au 1er septembre 2026\"\n",
    "    \"qui obligera pour les entreprises établies en France d'émettre et de recevoir des factures électroniques, \"\n",
    "    \"tu étudies les différentes plateformes de dématérialisation partenaire (PDP).\"\n",
    "    \"Tu utilise le contexte ci-dessous pour répondre aux questions :\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    "    \"\\n\\n\"\n",
    "    \"Tu ajoutes systématiqument les sources à tes réponses.\"\n",
    "    \"Si tu ne connais pas la réponse, réponds je ne sais pas.\"\n",
    "    \"Tes réponses doivent être simples, courtes et de quatres phrases au maximum.\"\n",
    "    \"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754062d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 docs in https://www.avalara.com/eu/fr\n",
      "71 chunks in https://www.avalara.com/eu/fr\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a retriver from an url\n",
    "retriever = await vector_store_create(\"https://www.avalara.com/eu/fr\")\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b600c096-246f-4455-a8a3-ea82c08ad9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oui, Avalara propose une plateforme de dématérialisation partenaire (PDP) qui facilite l'échange de factures électroniques. Cette solution permet d'automatiser la création, la transmission et l'archivage des factures tout en assurant la conformité avec les réglementations nationales. De plus, elle gère des échanges via des réseaux comme Peppol. Cela optimise également les processus financiers des entreprises. \n",
      "\n",
      "(Source : contexte fourni)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Est-ce que l'éditeur de logiciel propose bien une plateforme de dématérialisation partenaire (PDP) pour l'échange des factures ?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199e268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
