{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dfe691-baaa-478e-a273-939e2837a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fcb92-ab6b-4ca0-937a-56ab2bd6d2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Load a github repo \n",
    "\n",
    "if not os.environ.get(\"GITHUB_PAT\"):\n",
    "  os.environ[\"GITHUB_PAT\"] = getpass.getpass(\"Enter Github PAT: \")\n",
    "  \n",
    "async def github_repo(repo_name: str) -> list[Document]:\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name, # the repo name\n",
    "        access_token=os.environ[\"GITHUB_PAT\"],\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        branch =\"master\", \n",
    "        file_filter=lambda file_path: file_path.endswith(\n",
    "            \".md\"\n",
    "        ),  # load all markdowns files.\n",
    "    )\n",
    "    github_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        github_docs.append(doc)\n",
    "    return github_docs\n",
    "\n",
    "githubDoc = await github_repo(\"xBimTeam/XbimEssentials\")\n",
    "print(len(githubDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44613930-7ff6-4d02-8661-914f0a526ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "githubDoc2 = await github_repo(\"xBimTeam/XbimWebUI\")\n",
    "print(len(githubDoc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7529ceff-56f0-4465-9f79-f9208acdb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "async def website_parser(base_url: str) -> list[Document]:\n",
    "    loader = RecursiveUrlLoader(\n",
    "        base_url,\n",
    "        extractor=bs4_extractor,\n",
    "        max_depth=2,\n",
    "        prevent_outside=True,\n",
    "        # use_async=False,\n",
    "        # extractor=None,\n",
    "        # metadata_extractor=None,\n",
    "        # exclude_dirs=(),\n",
    "        # timeout=10,\n",
    "        # check_response_status=True,\n",
    "        # continue_on_failure=True,\n",
    "        # \n",
    "        # base_url=None,\n",
    "        # ...\n",
    "    )\n",
    "    site_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        site_docs.append(doc)\n",
    "    return site_docs\n",
    "\n",
    "website_docs = await website_parser(\"https://docs.xbim.net/\")\n",
    "print(len(website_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22202c4d-bd06-4882-ace9-64934fd58b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "460\n"
     ]
    }
   ],
   "source": [
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(              \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "documents = website_docs + githubDoc + githubDoc2\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(len(documents))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631176fb-2927-4970-b591-2e5a7b892abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Azure:  ········\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Store embeddings into the vector store\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Retrieve relevant information using similarity search\n",
    "retriever = vector_store.as_retriever() # uses similarity search by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c31472-ae52-4acf-bf09-b39c6df20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"You are a specialist of Building Information modeling looking for a web-based building model viewer\"    \n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"Add sources like links to your answer.\"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    \"Use four sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b600c096-246f-4455-a8a3-ea82c08ad9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The software editor behind this solution is the Xbim toolkit. It is an open-source library designed for building information modeling (BIM) and enables developers to create, edit, and visualize IFC (Industry Foundation Classes) models. Over the years, Xbim has matured significantly, becoming a stable and comprehensive framework for BIM applications. It provides essential tools for managing geometry and data manipulation, making it a valuable resource for architects and engineers in their BIM workflows. For more information, you can visit [Xbim's official website](http://docs.xbim.net/).\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Please describe the software editor behind this solution (name, description, history, \"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444634a0-f9b1-4adb-828f-2a72608426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The xbim toolkit is an open-source software development toolkit, which means it is available for free under its associated licenses. There are no mentioned fees or pricing models for using the xbim toolkit to read, create, or view Building Information Models. You can find more information regarding licenses on their official website [here](https://xbimteam.github.io/).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the price or licencing model of the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aac5bf2-a70d-4eb6-bce3-18527228d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Xbim Toolkit supports the following input formats: STEP, IfcXml, and IfcZip. It enables developers to read and write the full schema of IFC2x3, as well as handle BuildingSmart Building Collaboration Format (BCF), COBie Export, and BuildingSmart mvdXML. For more information, you can visit the [Xbim documentation site](http://docs.xbim.net/).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Can you list all the input format accepted by the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "291604d0-bc68-4d85-ad77-2c3d4dd89422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web viewer uses the WexBIM data format as its input, which is a custom binary data format produced using core xBIM Libraries. For more details on creating WexBIM files, you can refer to the documentation [here](http://docs.xbim.net/examples/creating-wexbim-file.html).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the format used in the web viewer ?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a00bd79-2e96-42b9-b773-e5566bcdb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WexBIM is a data format used for web presentation of building models, specifically optimized for use with the xBIM toolkit. It contains geometry data converted from IFC (Industry Foundation Classes) files, allowing for efficient 3D visualization in web-based applications. The WexBIM format enables the visualization of building information models in a lightweight manner suitable for online environments. For more information, you can visit the xBIM website: [xBIM](http://docs.xbim.net).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the WexBIM data format?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46a7e8ef-6db6-4dae-8895-8e52dc5b20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main programming languages used in the xbim solution are C# for backend code generation and JavaScript for the web-based visualization using WebGL. Additionally, T4 templates and GPPG/GPLEX parser generator are utilized for code generation purposes. The toolkit is designed to be integrated and utilized in .NET environments.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the main programming language used in the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572269cf-4dcf-4b27-a17a-6a56ea2b718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Xbim Toolkit is made available under the CDDL Open Source license. This license supports commercial usage of the XBIM system within a 'Larger Work', as long as the license agreements are honored. Additionally, the toolkit uses various third-party software packages, each under their respective licenses, including the New BSD License, OPEN CASCADE Public License, MS Permissive License, Apache 2.0 License, and MIT License. For more details, you can refer to the official documentation [here](https://github.com/xBimTeam/XbimWindowsUI).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the licences for Xbim Toolkit?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74e297-4f30-4c7b-b52b-fd03505eaa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
