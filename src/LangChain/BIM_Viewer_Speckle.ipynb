{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76dfe691-baaa-478e-a273-939e2837a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fcb92-ab6b-4ca0-937a-56ab2bd6d2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Load a github repo \n",
    "if not os.environ.get(\"GITHUB_PAT\"):\n",
    "  os.environ[\"GITHUB_PAT\"] = getpass.getpass(\"Enter Github PAT: \")\n",
    "\n",
    "async def github_repo(repo_name: str) -> list[Document]:\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name, # the repo name\n",
    "        access_token=os.environ[\"GITHUB_PAT\"],\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        file_filter=lambda file_path: file_path.endswith(\n",
    "            \".md\"\n",
    "        ),  # load all markdowns files.\n",
    "    )\n",
    "    github_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        github_docs.append(doc)\n",
    "    return github_docs\n",
    "\n",
    "githubDoc = await github_repo(\"specklesystems/speckle-server\")\n",
    "print(len(githubDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7529ceff-56f0-4465-9f79-f9208acdb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "async def website_parser(base_url: str) -> list[Document]:\n",
    "    loader = RecursiveUrlLoader(\n",
    "        base_url,\n",
    "        extractor=bs4_extractor,\n",
    "        max_depth=2,\n",
    "        prevent_outside=True,\n",
    "        # use_async=False,\n",
    "        # extractor=None,\n",
    "        # metadata_extractor=None,\n",
    "        # exclude_dirs=(),\n",
    "        # timeout=10,\n",
    "        # check_response_status=True,\n",
    "        # continue_on_failure=True,\n",
    "        # \n",
    "        # base_url=None,\n",
    "        # ...\n",
    "    )\n",
    "    site_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        site_docs.append(doc)\n",
    "    return site_docs\n",
    "\n",
    "website_docs = await website_parser(\"https://www.speckle.systems/\")\n",
    "print(len(website_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7bff32f-0dc1-4dfc-86c5-2e7ecac3bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "help_docs = await website_parser(\"https://speckle.guide/\")\n",
    "print(len(help_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22202c4d-bd06-4882-ace9-64934fd58b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "934\n"
     ]
    }
   ],
   "source": [
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(              \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "documents = website_docs + githubDoc + help_docs\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(len(documents))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "631176fb-2927-4970-b591-2e5a7b892abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Azure:  ········\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Store embeddings into the vector store\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Retrieve relevant information using similarity search\n",
    "retriever = vector_store.as_retriever() # uses similarity search by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3c31472-ae52-4acf-bf09-b39c6df20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"You are a specialist of Building Information modeling looking for a web-based building model viewer\"    \n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"Add sources like links to your answer.\"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    \"Use four sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b600c096-246f-4455-a8a3-ea82c08ad9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The software editor behind this solution is Speckle. Speckle is a cloud-based platform designed to enhance collaboration and automation in Architecture, Engineering, and Construction (AEC) projects. It allows users to connect various applications and automate processes to boost productivity and ensure real-time updates in building models. While the detailed history of Speckle isn't provided in the retrieved context, it has become significant in the AEC industry for its ability to streamline workflows and improve data flexibility. For more information, you can visit their official website at [Speckle](https://speckle.systems).\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Please describe the software editor behind this solution (name, description, history, \"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "444634a0-f9b1-4adb-828f-2a72608426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pricing model for Autodesk's solutions includes a token expenditure system where converting models costs a certain number of tokens, with 10 tokens estimated to cost approximately $30, and options for monthly plans, such as $450 for converting 20 models 15 days a month. On the other hand, Speckle offers a free, open-source platform option with distinctions between personal, professional, and educational use cases, and provides free unlimited server storage for educators and students. Further specific pricing details will depend on the exact product and usage needs. You can find more information directly on their respective websites, such as Autodesk and Speckle.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the price or licencing model of the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3aac5bf2-a70d-4eb6-bce3-18527228d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The supported input formats include Blender, Unity, ETABS, SAP2000, CSiBridge, SAFE, SketchUp, MicroStation, OpenRoads, OpenRail, OpenBuildings, Tekla Structures, Archicad, and Navisworks. Each of these applications has specific limitations regarding object conversions that are outlined in the Speckle documentation. For the most up-to-date details, you can refer to the Speckle user guide linked here: [Speckle Documentation](https://speckle.guide).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Can you list all the input format accepted by the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "291604d0-bc68-4d85-ad77-2c3d4dd89422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threejs extension for Speckle allows you to display 3D data in a web browser using the Speckle viewer, which is built on top of Three.js. This extension enables rapid rendering of large 3D models directly in your browser, making it an effective tool for visualizing building information models. You can find more details and access the package on its [npm page](https://www.npmjs.com/package/@speckle/viewer).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the threejs extension?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46a7e8ef-6db6-4dae-8895-8e52dc5b20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not specify the main programming languages used in the solution. Therefore, I can't provide an answer regarding the programming languages used.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the main programming language used in the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "572269cf-4dcf-4b27-a17a-6a56ea2b718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speckle is licensed under the Apache License 2.0. This license allows users to study, modify, redistribute, and commercialize any parts of the software. As a result, you can deploy your own Speckle server independently, without relying on the original creators. For more information, you can check their official documentation.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the licences for Speckle?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74e297-4f30-4c7b-b52b-fd03505eaa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
