{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dfe691-baaa-478e-a273-939e2837a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "import os\n",
    "import getpass\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fcb92-ab6b-4ca0-937a-56ab2bd6d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a github repo\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PAT\"):\n",
    "  os.environ[\"GITHUB_PAT\"] = getpass.getpass(\"Enter Github PAT: \")\n",
    "\n",
    "async def github_repo(repo_name: str) -> list[Document]:\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name, # the repo name\n",
    "        access_token= os.environ[\"GITHUB_PAT\"],\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        file_filter=lambda file_path: file_path.endswith(\n",
    "            \".md\"\n",
    "        ),  # load all markdowns files.\n",
    "    )\n",
    "    github_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        github_docs.append(doc)\n",
    "    return github_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7529ceff-56f0-4465-9f79-f9208acdb788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "async def website_parser(base_url: str) -> list[Document]:\n",
    "    loader = RecursiveUrlLoader(\n",
    "        base_url,\n",
    "        extractor=bs4_extractor,\n",
    "        max_depth=2,\n",
    "        prevent_outside=True,\n",
    "        # use_async=False,\n",
    "        # extractor=None,\n",
    "        # metadata_extractor=None,\n",
    "        # exclude_dirs=(),\n",
    "        # timeout=10,\n",
    "        # check_response_status=True,\n",
    "        # continue_on_failure=True,\n",
    "        # \n",
    "        # base_url=None,\n",
    "        # ...\n",
    "    )\n",
    "    site_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        site_docs.append(doc)\n",
    "    return site_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff77ade-2921-4db9-b5e7-f334488763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "azureEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(              \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embedding=azureEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ebe41a-4803-4dad-af73-51270f376be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 docs in https://speckle.guide/\n",
      "398 chunks in https://speckle.guide/\n",
      "23 docs in https://www.speckle.systems/\n",
      "441 chunks in https://www.speckle.systems/\n"
     ]
    }
   ],
   "source": [
    "# Define a list of site to parse\n",
    "urls = [\"https://speckle.guide/\",\"https://www.speckle.systems/\"]\n",
    "\n",
    "# Iterate over each urls in the list\n",
    "for url in urls:\n",
    "    # Retrive the documents\n",
    "    website_docs = await website_parser(url)\n",
    "    website_docs\n",
    "    print(f\"{len(website_docs)} docs in {url}\")\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(website_docs)\n",
    "    print(f\"{len(chunks)} chunks in {url}\")\n",
    "    # Add embeddings into the vector store\n",
    "    vector_store.add_documents(documents=chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ef82dc-3616-4856-8a75-8a768a8231bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.github.com/repos/specklesystems/speckle-server/git/trees/master?recursive=1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate over each urls in the list\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m repos:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Retrive the documents\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     github_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m github_repo(repo)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(github_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m docs in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Split the documents into chunks\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mgithub_repo\u001b[1;34m(repo_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m loader \u001b[38;5;241m=\u001b[39m GithubFileLoader(\n\u001b[0;32m      8\u001b[0m     repo\u001b[38;5;241m=\u001b[39mrepo_name, \u001b[38;5;66;03m# the repo name\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     access_token\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGITHUB_PAT\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     ),  \u001b[38;5;66;03m# load all markdowns files.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m github_docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39malazy_load():\n\u001b[0;32m     18\u001b[0m     github_docs\u001b[38;5;241m.\u001b[39mappend(doc)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m github_docs\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:83\u001b[0m, in \u001b[0;36mBaseLoader.alazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mnext\u001b[39m, iterator, done)  \u001b[38;5;66;03m# type: ignore[call-arg, arg-type]\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m done:\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:588\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[1;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    590\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, wrapper)),\n\u001b[0;32m    591\u001b[0m     )\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(executor_or_config, wrapper)\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:579\u001b[0m, in \u001b[0;36mrun_in_executor.<locals>.wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\github.py:225\u001b[0m, in \u001b[0;36mGithubFileLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m--> 225\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_file_paths()\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m    227\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_file_content_by_path(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\github.py:193\u001b[0m, in \u001b[0;36mGithubFileLoader.get_file_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m base_url \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgithub_api_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/repos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/git/trees/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?recursive=1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m )\n\u001b[0;32m    192\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(base_url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m--> 193\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    194\u001b[0m all_files \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" one element in all_files\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m{\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    'path': '.github', \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m}\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.github.com/repos/specklesystems/speckle-server/git/trees/master?recursive=1"
     ]
    }
   ],
   "source": [
    "# Define a list of github repo to parse\n",
    "repos = [\"specklesystems/speckle-server\"]\n",
    "\n",
    "# Iterate over each urls in the list\n",
    "for repo in repos:\n",
    "    # Retrive the documents\n",
    "    github_docs = await github_repo(repo)\n",
    "    print(f\"{len(github_docs)} docs in {repo}\")\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(github_docs)\n",
    "    print(f\"{len(chunks)} chunks in {repo}\")\n",
    "    # Add embeddings into the vector store\n",
    "    vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85e1fc51-1131-461c-961a-e38f211010bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant information using similarity search\n",
    "retriever = vector_store.as_retriever() # uses similarity search by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3c31472-ae52-4acf-bf09-b39c6df20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"You are a specialist of Building Information modeling looking for a web-based building model viewer\"    \n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"Add sources like links to your answer.\"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    \"Use four sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b600c096-246f-4455-a8a3-ea82c08ad9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have specific information about the software editor behind the BIM viewer solution mentioned. The retrieved context primarily focuses on features and functionalities of the viewer rather than providing details about its development or history. Therefore, I'm unable to provide the name, description, or history of the software editor.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Please describe the software editor behind this solution (name, description, history, \"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "444634a0-f9b1-4adb-828f-2a72608426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The licensing model for the BIMData solution includes several tiers: the Starter plan is free (0€ per year), the Professional plan starts at 540€ per year, and the Enterprise plan begins at 2500€ per year. For the on-premise option, pricing is provided upon request. Each plan comes with different storage capacities and features tailored to various project sizes and needs. More details can be found on their website: [BIMData Pricing](https://bimdata.com).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the price or licencing model of the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aac5bf2-a70d-4eb6-bce3-18527228d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution accepts a variety of input formats including number, password, range, search, telephone, text, time, URL, week, select dropdowns, and textarea. Additionally, it supports date, datetime, datetime-local, email, and month inputs. For each format, there are also read-only and disabled states. Unfortunately, specific solutions available for Building Information Modeling were not outlined in the retrieved context.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Can you list all the input format accepted by the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "291604d0-bc68-4d85-ad77-2c3d4dd89422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specific format used in a web-based building model viewer typically includes standards like IFC (Industry Foundation Classes) or other formats like COLLADA, FBX, or proprietary formats optimized for visualization. However, the exact format may vary depending on the viewer's implementation. For more detailed information, it would be best to refer to the documentation of the specific viewer SDK you are using. Unfortunately, I don't have the specific information on the format used in the web viewer without additional context.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the format used in the web viewer ?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a00bd79-2e96-42b9-b773-e5566bcdb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WexBIM data format is a proprietary format developed for exchanging building information models (BIM) with a focus on interoperability. It is designed to facilitate the sharing and collaboration of BIM data among various software applications and stakeholders in the construction industry. For more detailed information, you might refer to the official documentation or respective resources related to WexBIM. Unfortunately, I don't have specific links to provide.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the WexBIM data format?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46a7e8ef-6db6-4dae-8895-8e52dc5b20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved context does not specify the main programming languages used in the BIMData.io solution. You may need to contact their support or refer to their documentation for detailed technical information. If you need further assistance, please let me know!\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the main programming language used in the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "572269cf-4dcf-4b27-a17a-6a56ea2b718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have specific information on the licenses for BIMData. You may need to check their official website or contact them directly for detailed licensing information. You can visit [BIMData](https://bimdata.io) for more resources.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the licences for BIMData?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74e297-4f30-4c7b-b52b-fd03505eaa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
