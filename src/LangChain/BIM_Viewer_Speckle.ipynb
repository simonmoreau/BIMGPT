{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dfe691-baaa-478e-a273-939e2837a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "import os\n",
    "import getpass\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7fcb92-ab6b-4ca0-937a-56ab2bd6d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a github repo\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PAT\"):\n",
    "  os.environ[\"GITHUB_PAT\"] = getpass.getpass(\"Enter Github PAT: \")\n",
    "\n",
    "async def github_repo(repo_name: str) -> list[Document]:\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name, # the repo name\n",
    "        access_token= os.environ[\"GITHUB_PAT\"],\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        file_filter=lambda file_path: file_path.endswith(\n",
    "            \".md\"\n",
    "        ),  # load all markdowns files.\n",
    "    )\n",
    "    github_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        github_docs.append(doc)\n",
    "    return github_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7529ceff-56f0-4465-9f79-f9208acdb788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "async def website_parser(base_url: str) -> list[Document]:\n",
    "    loader = RecursiveUrlLoader(\n",
    "        base_url,\n",
    "        extractor=bs4_extractor,\n",
    "        max_depth=2,\n",
    "        prevent_outside=True,\n",
    "        # use_async=False,\n",
    "        # extractor=None,\n",
    "        # metadata_extractor=None,\n",
    "        # exclude_dirs=(),\n",
    "        # timeout=10,\n",
    "        # check_response_status=True,\n",
    "        # continue_on_failure=True,\n",
    "        # \n",
    "        # base_url=None,\n",
    "        # ...\n",
    "    )\n",
    "    site_docs = []\n",
    "    async for doc in loader.alazy_load():\n",
    "        site_docs.append(doc)\n",
    "    return site_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff77ade-2921-4db9-b5e7-f334488763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "azureEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(              \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embedding=azureEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ebe41a-4803-4dad-af73-51270f376be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 docs in https://speckle.guide/\n",
      "398 chunks in https://speckle.guide/\n",
      "23 docs in https://www.speckle.systems/\n",
      "441 chunks in https://www.speckle.systems/\n"
     ]
    }
   ],
   "source": [
    "# Define a list of site to parse\n",
    "urls = [\"https://speckle.guide/\",\"https://www.speckle.systems/\"]\n",
    "\n",
    "# Iterate over each urls in the list\n",
    "for url in urls:\n",
    "    # Retrive the documents\n",
    "    website_docs = await website_parser(url)\n",
    "    website_docs\n",
    "    print(f\"{len(website_docs)} docs in {url}\")\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(website_docs)\n",
    "    print(f\"{len(chunks)} chunks in {url}\")\n",
    "    # Add embeddings into the vector store\n",
    "    vector_store.add_documents(documents=chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ef82dc-3616-4856-8a75-8a768a8231bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 docs in specklesystems/speckle-server\n",
      "95 chunks in specklesystems/speckle-server\n"
     ]
    }
   ],
   "source": [
    "# Define a list of github repo to parse\n",
    "repos = [\"specklesystems/speckle-server\"]\n",
    "\n",
    "# Iterate over each urls in the list\n",
    "for repo in repos:\n",
    "    # Retrive the documents\n",
    "    github_docs = await github_repo(repo)\n",
    "    print(f\"{len(github_docs)} docs in {repo}\")\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(github_docs)\n",
    "    print(f\"{len(chunks)} chunks in {repo}\")\n",
    "    # Add embeddings into the vector store\n",
    "    vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e1fc51-1131-461c-961a-e38f211010bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant information using similarity search\n",
    "retriever = vector_store.as_retriever() # uses similarity search by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c31472-ae52-4acf-bf09-b39c6df20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"You are a specialist of Building Information modeling looking for a web-based building model viewer\"    \n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"Add sources like links to your answer.\"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    \"Use four sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b600c096-246f-4455-a8a3-ea82c08ad9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The software editor behind this solution is Speckle. Speckle is a cloud-based platform designed to facilitate collaboration and data management in architecture, engineering, and construction (AEC) projects. It allows teams to automate processes, capture real-time updates, and integrate with a variety of other applications through its support for over 25 plugins. Speckle has gained recognition for enhancing collaboration and decision-making in complex design projects within the AEC sector.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Please describe the software editor behind this solution (name, description, history, \"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "444634a0-f9b1-4adb-828f-2a72608426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pricing and licensing for Autodesk services typically involve a token expenditure model, where you might pay approximately $30 for converting models, like 20 Revit models, which can accumulate to around $450 per month if used frequently. Additionally, fees are applicable for usage exceeding agreed limits and are invoiced for payment within 30 days. In contrast, Speckle offers free options for educational use and provides tiered pricing for personal and professional use. For precise pricing details, please refer to the official websites of these services.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the price or licencing model of the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aac5bf2-a70d-4eb6-bce3-18527228d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input formats accepted by the Speckle solution include various building modeling applications as follows: Blender, Unity, ETABS, SAP2000, CSiBridge, SAFE, SketchUp, MicroStation, OpenRoads, OpenRail, OpenBuildings, Tekla Structures, Archicad, and Navisworks. Each application may have different levels of support for object conversions. For specific details about unsupported elements and limitations, you may refer to the official documentation.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Can you list all the input format accepted by the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "291604d0-bc68-4d85-ad77-2c3d4dd89422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web viewer, specifically the Speckle viewer, primarily uses a custom format for 3D models that is efficient for rendering and manipulation in web browsers. This format leverages a data tree structure specific to Speckle's API for handling complex model data. For more detailed information about the supported data structures, you can refer to the full documentation [here](https://speckle.guide/viewer/).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the format used in the web viewer ?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a00bd79-2e96-42b9-b773-e5566bcdb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have information about the WexBIM data format.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is the WexBIM data format?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46a7e8ef-6db6-4dae-8895-8e52dc5b20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main programming languages used in Speckle, a web-based building model viewer, include C#, JavaScript, and TypeScript. These languages facilitate the integration and customization of the platform through its API and user interface elements. Additionally, Speckle's ability to support over 25 plugins indicates a versatile use of various programming languages depending on the plugins developed. For more detailed information, you can visit [Speckle's website](https://speckle.systems/).\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the main programming language used in the solution?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "572269cf-4dcf-4b27-a17a-6a56ea2b718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have information on the licenses for BIMData. You may need to consult the official BIMData website or their documentation for accurate licensing details.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What are the licences for BIMData?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74e297-4f30-4c7b-b52b-fd03505eaa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
