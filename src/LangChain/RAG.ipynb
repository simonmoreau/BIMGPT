{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040f8985-9348-46d6-bd2b-ff9d408e0e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoreau\\AppData\\Local\\Temp\\ipykernel_37996\\1614319664.py:12: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(html, \"lxml\")\n",
      "C:\\Users\\smoreau\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\recursive_url_loader.py:43: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(raw_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@aminajavaid30/building-a-rag-system-synthesis-67f36efa7c35\n",
    "\n",
    "# Data Ingestion & Retrieval\n",
    "import bs4\n",
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load a website reccusivly and split it into chunks\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "loader = RecursiveUrlLoader(\n",
    "    \"https://www.corneliadixit.com/\",\n",
    "    extractor=bs4_extractor,\n",
    "    max_depth=2,\n",
    "    prevent_outside=True,\n",
    "    # use_async=False,\n",
    "    # extractor=None,\n",
    "    # metadata_extractor=None,\n",
    "    # exclude_dirs=(),\n",
    "    # timeout=10,\n",
    "    # check_response_status=True,\n",
    "    # continue_on_failure=True,\n",
    "    # \n",
    "    # base_url=None,\n",
    "    # ...\n",
    ")\n",
    "documents = []\n",
    "async for doc in loader.alazy_load():\n",
    "    documents.append(doc)\n",
    "\n",
    "# Initialize the recursive character text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(              \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(len(documents))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631176fb-2927-4970-b591-2e5a7b892abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Azure:  ········\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Store embeddings into the vector store\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Retrieve relevant information using similarity search\n",
    "retriever = vector_store.as_retriever() # uses similarity search by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbd4817b-1efc-4ea3-b12e-f65f6430d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur le site, les patrons pour poupées incluent le pyjama Pimprenelle et la robe-tablier Matilda. Ils sont conçus pour créer des pièces incontournables dans la garde-robe des poupées.\n"
     ]
    }
   ],
   "source": [
    "# Q/A Retrieval Chain\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the Azure AI LLM with the specific model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-bim42-test-fr-ai.openai.azure.com\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# Define the system prompt that instructs the LLM how to answer questions based on retrieved context\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # Placeholder for the retrieved context\n",
    ")\n",
    "\n",
    "# Create a chat prompt template with a system message and human message\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # System message contains instructions and context\n",
    "        (\"human\", \"{input}\"),  # Human message includes the user's input question\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a document chain that combines the LLM with the prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Combine the retrieval chain with the question-answering chain \n",
    "# The retrieval chain retrieves relevant documents and feeds them into the question-answering chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Invoke the chain with a question, and the retriever will provide context for the LLM to generate an answer\n",
    "response = retrieval_chain.invoke({\"input\": \"Quels sont les patrons pour poupées sur le site ?\"})\n",
    "\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7e8ef-6db6-4dae-8895-8e52dc5b20c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
